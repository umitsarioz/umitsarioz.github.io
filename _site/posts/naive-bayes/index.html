<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en" >
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  ><!-- Setup Open Graph image -->

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Naive Bayes Simplified From Theory to Code" />
<meta property="og:locale" content="en" />
<meta name="description" content="Naive Bayes is a family of probabilistic classifiers based on Bayes’ theorem with the “naive” assumption that features are conditionally independent given the class label. Despite this simplification, Naive Bayes classifiers often perform remarkably well on a variety of problems, especially with text classification and real-world datasets. This blog post explores the foundation of Bayes’ theorem, its formula, and applications in real life." />
<meta property="og:description" content="Naive Bayes is a family of probabilistic classifiers based on Bayes’ theorem with the “naive” assumption that features are conditionally independent given the class label. Despite this simplification, Naive Bayes classifiers often perform remarkably well on a variety of problems, especially with text classification and real-world datasets. This blog post explores the foundation of Bayes’ theorem, its formula, and applications in real life." />
<link rel="canonical" href="http://localhost:4000/posts/naive-bayes/" />
<meta property="og:url" content="http://localhost:4000/posts/naive-bayes/" />
<meta property="og:site_name" content="Ümit Sarıöz" />
<meta property="og:image" content="http://localhost:4000/assets/img/ss/2023-04-18-naive-bayes/first.webp" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-04-18T00:00:00+03:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/assets/img/ss/2023-04-18-naive-bayes/first.webp" />
<meta property="twitter:title" content="Naive Bayes Simplified From Theory to Code" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-18T00:00:00+03:00","datePublished":"2023-04-18T00:00:00+03:00","description":"Naive Bayes is a family of probabilistic classifiers based on Bayes’ theorem with the “naive” assumption that features are conditionally independent given the class label. Despite this simplification, Naive Bayes classifiers often perform remarkably well on a variety of problems, especially with text classification and real-world datasets. This blog post explores the foundation of Bayes’ theorem, its formula, and applications in real life.","headline":"Naive Bayes Simplified From Theory to Code","image":"http://localhost:4000/assets/img/ss/2023-04-18-naive-bayes/first.webp","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/naive-bayes/"},"url":"http://localhost:4000/posts/naive-bayes/"}</script>
<!-- End Jekyll SEO tag -->


  <title>Naive Bayes Simplified | From Theory to Code | Ümit Sarıöz
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">

  <link rel="manifest" href="/assets/img/favicons/site.webmanifest">

<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Ümit Sarıöz">
<meta name="application-name" content="Ümit Sarıöz">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  <!-- Resource Hints -->
  
    
      
        <link rel="preconnect" href="https://fonts.googleapis.com" >
      
        <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
      
    
      
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      
        <link rel="dns-prefetch" href="https://fonts.gstatic.com" >
      
    
      
        <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      
        <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
      
    
  

  <!-- Bootstrap -->
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css">
  

  <!-- Theme style -->
  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  <!-- Web Font -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  <!-- Font Awesome Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css">

  <!-- 3rd-party Dependencies -->

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Image Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css">
  

  <!-- Scripts -->

  <script src="/assets/js/dist/theme.min.js"></script>

  <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script>







<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script async src="/assets/js/data/mathjax.js"></script>
  <script async src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>


<!-- Pageviews -->

  

  
    
        
          <!-- Display GoatCounter pageviews -->
<script>
  document.addEventListener('DOMContentLoaded', () => {
    const pv = document.getElementById('pageviews');

    if (pv !== null) {
      const uri = location.pathname.replace(/\/$/, '');
      const url = `https://umitsarioz.goatcounter.com/counter/${encodeURIComponent(uri)}.json`;

      fetch(url)
        .then((response) => response.json())
        .then((data) => {
          const count = data.count.replace(/\s/g, '');
          pv.innerText = new Intl.NumberFormat().format(count);
        })
        .catch((error) => {
          pv.innerText = '1';
        });
    }
  });
</script>

        
    
  



  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <!--
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/core/avatar_ai.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a>

    <a class="site-title d-block" href="/">Ümit Sarıöz</a>
    <p class="site-subtitle fst-italic mb-0">AI & Tech. Bloge</p>
  </header>
-->
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/blog-timeline/" class="nav-link">
            <i class="fa-fw fa-fw fas fa-timeline"></i>
            

            <span>BLOG TIMELINE</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/projects/" class="nav-link">
            <i class="fa-fw fa-fw fas fa-code ml-xl-3 mr-xl-3 unloaded"></i>
            

            <span>PROJECTS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://www.linkedin.com/in/umitsarioz"
          aria-label="linkedin"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-linkedin"></i>
        </a>
      
    
      

      
        <a
          href="https://github.com/umitsarioz"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['umitsariozz','gmail.com'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">Home</a>
            </span>

          
        
          
        
          
            
              <span>Naive Bayes Simplified | From Theory to Code</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search id="search" class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->




  
  

  
    
      
      
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  

  


<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  

  
  

  




<!-- return -->










<article class="px-1" data-toc="true">
  <header>
    <h1 data-toc-skip>Naive Bayes Simplified | From Theory to Code</h1>
    
      <p class="post-desc fw-light mb-4">Naive Bayes is a family of probabilistic classifiers based on Bayes' theorem with the "naive" assumption that features are conditionally independent given the class label. Despite this simplification, Naive Bayes classifiers often perform remarkably well on a variety of problems, especially with text classification and real-world datasets. This blog post explores the foundation of Bayes' theorem, its formula, and applications in real life.</p>
    

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1681765200"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Apr 18, 2023
</time>

      </span>

      <!-- lastmod date -->
      

      
        
        
        

        

        <div class="mt-3 mb-3">
          <a href="/assets/img/ss/2023-04-18-naive-bayes/first.webp" class="popup img-link preview-img shimmer"><img src="/assets/img/ss/2023-04-18-naive-bayes/first.webp"  alt="Preview Image" width="1200" height="630"  loading="lazy"></a></div>
      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              <a href="https://www.linkedin.com/in/umitsarioz">Ümit Sarıöz</a>
            
          </em>
        </span>

        <div>
          <!-- pageviews -->
          
            <span>
              <em id="pageviews">
                <i class="fas fa-spinner fa-spin small"></i>
              </em>
              views
            </span>
          

          <!-- read time -->
          <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="1600 words"
>
  <em>8 min</em> read</span>

        </div>
      </div>
    </div>
  </header>

  
    <div id="toc-bar" class="d-flex align-items-center justify-content-between invisible">
      <span class="label text-truncate">Naive Bayes Simplified | From Theory to Code</span>
      <button type="button" class="toc-trigger btn me-1">
        <i class="fa-solid fa-list-ul fa-fw"></i>
      </button>
    </div>

    <button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm">
      <span class="label ps-2 pe-1">Contents</span>
      <i class="fa-solid fa-angle-right fa-fw"></i>
    </button>

    <dialog id="toc-popup" class="p-0">
      <div class="header d-flex flex-row align-items-center justify-content-between">
        <div class="label text-truncate py-2 ms-4">Naive Bayes Simplified | From Theory to Code</div>
        <button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75">
          <i class="fas fa-close"></i>
        </button>
      </div>
      <div id="toc-popup-content" class="px-4 py-3 pb-4"></div>
    </dialog>
  

  <div class="content">
    <h2 id="introduction"><span class="me-2">Introduction</span><a href="#introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>In the realm of machine learning and statistical classification, Naive Bayes stands out as one of the simplest and most effective algorithms. Its name stems from the “naive” assumption of feature independence, which, despite being a strong assumption, often leads to surprisingly accurate results. This blog post will guide you through the fundamental concepts of Naive Bayes, demonstrating its utility through real-life examples and a detailed step-by-step mathematical exploration. We will also cover various types of Naive Bayes classifiers, each tailored for different types of data, and implement them from scratch in Python.</p>

<h3 id="bayes-theorem-foundation-and-formula"><span class="me-2">Bayes’ Theorem: Foundation and Formula</span><a href="#bayes-theorem-foundation-and-formula" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Bayes’ theorem is a fundamental concept in probability theory and statistics, providing a way to update the probability of a hypothesis based on new evidence. It is named after the Reverend Thomas Bayes, who formulated it in the 18th century.</p>

<p>The formula for Bayes’ theorem is:</p>

\[P(C \mid x) = \frac{P(x \mid C) \cdot P(C)}{P(x)}\]

<p>Where:</p>

<ul>
  <li>$P(C∣x)$ is the posterior probability of class $C$ given the feature $x$.</li>
  <li>$P(x∣C)$ is the likelihood of feature $x$ given class $C$.</li>
  <li>$P(C)$ is the prior probability of class $C$.</li>
  <li>$P(x)$ is the marginal probability of feature $x$.</li>
</ul>

<blockquote class="prompt-tip">
  <p><strong>Foundation:</strong> Bayes’ theorem provides a way to update our beliefs about the likelihood of a class given new evidence. In classification problems, this means we can calculate the probability of a data point belonging to a particular class based on its features.</p>
</blockquote>

<h2 id="real-life-usage-examples"><span class="me-2">Real-Life Usage Examples</span><a href="#real-life-usage-examples" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>
    <p><strong>Spam Filtering:</strong> Naive Bayes is widely used in email spam filters. By analyzing the frequency of words in spam and non-spam emails, the classifier can predict whether a new email is spam.</p>
  </li>
  <li>
    <p><strong>Text Classification:</strong> In sentiment analysis or document categorization, Naive Bayes can classify text into different categories based on the frequency of words.</p>
  </li>
  <li>
    <p><strong>Medical Diagnosis:</strong> Naive Bayes can be used to predict the likelihood of a disease based on symptoms and medical history.</p>
  </li>
  <li>
    <p><strong>Recommendation Systems:</strong> Naive Bayes can help recommend products based on user behavior and preferences.</p>
  </li>
</ul>

<h2 id="basic-problem-and-mathematical-solution"><span class="me-2">Basic Problem and Mathematical Solution</span><a href="#basic-problem-and-mathematical-solution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Let’s solve a basic Naive Bayes problem step-by-step.</p>

<p>** Problem Statement:** Suppose we have a dataset with two features $x_1$​ and $x_2$​ and a binary class label $C$. We want to classify a new data point ($x_1^′$,$x_2^′$).</p>

<p><a href="/assets/img/ss/2023-04-18-naive-bayes/bayes2.png" class="popup img-link  shimmer"><img src="/assets/img/ss/2023-04-18-naive-bayes/bayes2.png" alt="parts" loading="lazy"></a></p>

<h2 id="step-1-calculate-prior-probabilities"><span class="me-2">Step 1: Calculate Prior Probabilities</span><a href="#step-1-calculate-prior-probabilities" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<blockquote class="prompt-info">
  <p><strong>Prior probability</strong> is the initial probability of a hypothesis (or class) before observing any data. It represents the baseline belief about the class before considering the evidence.</p>
</blockquote>

\[P(C) = \frac{\text{Number of instances in class } C}{\text{Total number of instances}} = \frac{N_c}{N}\]

<p>Where:</p>

<ul>
  <li>$P(C)$ is the prior probability of class $C$,</li>
  <li>$N_c$​ is the number of instances in class $C$​,</li>
  <li>$N$ is the total number of instances.
    <h2 id="step-2-calculate-likelihoods"><span class="me-2">Step 2: Calculate Likelihoods</span><a href="#step-2-calculate-likelihoods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
  </li>
</ul>

<blockquote class="prompt-info">
  <p><strong>Likelihood</strong> is the probability of observing the data given a particular hypothesis (or class). In Naive Bayes, it is the probability of the features given the class.</p>
</blockquote>

<p>For Gaussian Naive Bayes:
\(P(x_i \mid C) = \frac{1}{\sqrt{2 \pi \sigma_i^2}} \exp \left( -\frac{(x_i - \mu_i)^2}{2 \sigma_i^2} \right)\)</p>

<p>Where $μ_i$​ and $σ_i^2$​ are the mean and variance of feature $x_i$​ in class $C$.</p>

<h2 id="step-3-calculate-posterior-probability"><span class="me-2">Step 3: Calculate Posterior Probability</span><a href="#step-3-calculate-posterior-probability" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<blockquote class="prompt-tip">
  <p><strong>Marginal Probability $P(x)$:</strong> The overall probability of the features xx across all classes. It acts as a normalization factor to ensure that the posterior probabilities sum to 1.</p>
</blockquote>

<blockquote class="prompt-info">
  <p><strong>Posterior probability</strong> is the probability of a particular outcome or hypothesis after considering new evidence or data. It represents an updated belief about the hypothesis once the evidence is taken into account. In the context of Naive Bayes and Bayesian inference, it refers to the probability of a class given a set of features or observations.</p>
</blockquote>

\[P(C \mid x) = \frac{P(C) \prod_{i=1}^{d} P(x_i \mid C)}{P(x)}\]

<ul>
  <li>Where $d$ is the number of features.</li>
</ul>

<blockquote class="prompt-info">
  <p><strong>Naive Bayes Theorem</strong>
Naive Bayes is a classification technique based on Bayes’ theorem, assuming that the features are conditionally independent given the class label.</p>
</blockquote>

<blockquote class="prompt-tip">
  <p><b><u>Assumptions</u></b></p>
  <ul>
    <li><strong>Feature Independence:</strong> Features are independent of each other given the class label.</li>
    <li><strong>Class Prior Probability:</strong> The prior probability of each class is known.</li>
    <li><strong>Feature Likelihoods:</strong> The likelihood of each feature given the class is modeled using specific distributions (e.g., Gaussian, multinomial, Bernoulli).</li>
  </ul>
</blockquote>

<h2 id="types-of-naive-bayes-classifiers"><span class="me-2">Types of Naive Bayes Classifiers</span><a href="#types-of-naive-bayes-classifiers" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="gaussian-naive-bayes"><span class="me-2">Gaussian Naive Bayes:</span><a href="#gaussian-naive-bayes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li><strong>Usage:</strong> Best for continuous data where features follow a normal distribution.</li>
</ul>

\[\text{Formula} \rightarrow P(x_i \mid C) = \frac{1}{\sqrt{2 \pi \sigma_i^2}} \exp \left( -\frac{(x_i - \mu_i)^2}{2 \sigma_i^2} \right)\]

<blockquote class="prompt-tip">
  <p><strong><code class="language-plaintext highlighter-rouge">+</code></strong> Simple and efficient with continuous data; works well with normally distributed data.</p>
</blockquote>

<blockquote class="prompt-warning">
  <p><strong><code class="language-plaintext highlighter-rouge">-</code></strong> Assumes features are normally distributed, which may not always be true.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">GaussianNaiveBayes</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Gaussian Naive Bayes classifier for continuous data.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">priors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">):</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span>
            <span class="n">self</span><span class="p">.</span><span class="n">mean</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">X_c</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">var</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">X_c</span><span class="p">.</span><span class="nf">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">priors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_c</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_gaussian_density</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">mean</span><span class="p">[</span><span class="n">class_idx</span><span class="p">]</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">var</span><span class="p">[</span><span class="n">class_idx</span><span class="p">]</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">var</span><span class="p">))</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">var</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">posteriors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">):</span>
            <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">priors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">_gaussian_density</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">posteriors</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">+</span> <span class="n">likelihood</span>
            
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">posteriors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
</pre></td></tr></tbody></table></code></div></div>

<h3 id="multinomial-naive-bayes"><span class="me-2">Multinomial Naive Bayes:</span><a href="#multinomial-naive-bayes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li><strong>Usage:</strong> Suitable for discrete data, such as word counts in text classification.</li>
</ul>

\[\text{Formula} \rightarrow P(x_j \mid C) = \frac{N_{Cj} + \alpha}{N_C + \alpha \cdot |V|}\]

<blockquote class="prompt-tip">
  <p><strong><code class="language-plaintext highlighter-rouge">+</code></strong> Effective for text classification with large vocabularies; handles feature count data well.</p>
</blockquote>

<blockquote class="prompt-warning">
  <p><strong><code class="language-plaintext highlighter-rouge">-</code></strong> Assumes that feature counts are conditionally independent.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">MultinomialNaiveBayes</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Multinomial Naive Bayes classifier for discrete data.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">class_counts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">class_priors</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">class_counts</span> <span class="o">/</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feature_count</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">feature_count</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">c</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feature_totals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">feature_count</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">log_priors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">class_priors</span><span class="p">)</span>
        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">feature_count</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">feature_totals</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">])</span>
        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">log_posterior</span> <span class="o">=</span> <span class="n">log_priors</span> <span class="o">+</span> <span class="n">log_likelihoods</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">log_posterior</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
</pre></td></tr></tbody></table></code></div></div>

<h3 id="bernoulli-naive-bayes"><span class="me-2">Bernoulli Naive Bayes:</span><a href="#bernoulli-naive-bayes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li><strong>Usage:</strong> Ideal for binary/boolean features.</li>
</ul>

\[\text{Formula} \rightarrow P(x_j \mid C) = \frac{N_{Cj} + \alpha}{N_C + \alpha \cdot 2}\]

<blockquote class="prompt-tip">
  <p><strong><code class="language-plaintext highlighter-rouge">+</code></strong> Suitable for binary/boolean data; handles presence/absence features well.</p>
</blockquote>

<blockquote class="prompt-warning">
  <p><strong><code class="language-plaintext highlighter-rouge">-</code></strong> Assumes features are binary, which may not always be the case.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">BernoulliNaiveBayes</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Bernoulli Naive Bayes classifier for binary/boolean data.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">class_counts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">class_priors</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">class_counts</span> <span class="o">/</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feature_probs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">):</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span>
            <span class="n">self</span><span class="p">.</span><span class="n">feature_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X_c</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">X_c</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">log_priors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">class_priors</span><span class="p">)</span>
        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">feature_probs</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">feature_probs</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">log_posterior</span> <span class="o">=</span> <span class="n">log_priors</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">log_posterior</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
</pre></td></tr></tbody></table></code></div></div>

<h3 id="complement-naive-bayes"><span class="me-2">Complement Naive Bayes:</span><a href="#complement-naive-bayes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li><strong>Usage:</strong> Designed to handle imbalanced datasets better.</li>
</ul>

\[\text{Formula} \rightarrow P(x_j \mid C) = \frac{N_{C'j} + \alpha}{N_{C'} + \alpha \cdot |V|}\]

<blockquote class="prompt-tip">
  <p><strong><code class="language-plaintext highlighter-rouge">+</code></strong> Addresses class imbalance by using feature probabilities from the complement of each class.</p>
</blockquote>

<blockquote class="prompt-warning">
  <p><strong><code class="language-plaintext highlighter-rouge">-</code></strong> More complex to implement; may not perform well on balanced datasets.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">ComplementNaiveBayes</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Complement Naive Bayes classifier for imbalanced data.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">class_counts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">class_priors</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">class_counts</span> <span class="o">/</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feature_count</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">):</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span>
            <span class="n">self</span><span class="p">.</span><span class="n">feature_count</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X_c</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feature_totals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">feature_count</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">complement_feature_count</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span>
        <span class="n">self</span><span class="p">.</span><span class="n">complement_feature_totals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">complement_feature_count</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">log_priors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">class_priors</span><span class="p">)</span>
        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">feature_count</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">feature_totals</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">])</span>
        <span class="n">log_complement</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">complement_feature_count</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">complement_feature_totals</span><span class="p">)</span>
        <span class="n">log_complement</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">log_complement</span><span class="p">)</span>
        <span class="n">log_posterior</span> <span class="o">=</span> <span class="n">log_priors</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">log_likelihoods</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">log_complement</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">log_posterior</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="advantages-and-disadvantages-of-naive-bayes"><span class="me-2">Advantages and Disadvantages of Naive Bayes</span><a href="#advantages-and-disadvantages-of-naive-bayes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="advantages"><span class="me-2">Advantages:</span><a href="#advantages" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">Simplicity:</code></strong> Easy to understand and implement.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">Efficiency:</code></strong> Fast training and prediction.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">Scalability:</code></strong> Handles large datasets efficiently.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">Performance:</code></strong> Often performs well even with the naive independence assumption.</li>
</ul>

<h3 id="disadvantages"><span class="me-2">Disadvantages:</span><a href="#disadvantages" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">Conditional Independence Assumption:</code></strong> The assumption that features are independent given the class label may not hold true in practice.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">Feature Dependence:</code></strong> Correlated features can lead to poor performance.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">Gaussian Assumption:</code></strong> Gaussian Naive Bayes assumes normally distributed features, which may not always be valid.</li>
</ul>

<h2 id="conclusion"><span class="me-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Naive Bayes classifiers offer a powerful yet simple approach to classification problems. By leveraging Bayes’ theorem and assuming feature independence, these classifiers can efficiently handle a variety of data types and scales. While the conditional independence assumption can be a limitation, the classifiers’ efficiency and effectiveness often outweigh this drawback. From text classification to medical diagnosis, Naive Bayes provides a versatile tool for many real-world applications. By understanding the underlying principles and implementing these classifiers from scratch, you can better appreciate their strengths and tailor them to your specific needs.</p>

<p>Feel free to experiment with different Naive Bayes variants and see how they perform on your datasets. The simplicity and efficiency of Naive Bayes make it a valuable addition to any data scientist’s toolkit.</p>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/tags/algorithms/"
            class="post-tag no-text-decoration"
          >algorithms</a>
        
          <a
            href="/tags/machine-learning/"
            class="post-tag no-text-decoration"
          >machine-learning</a>
        
          <a
            href="/tags/supervised-learning/"
            class="post-tag no-text-decoration"
          >supervised-learning</a>
        
          <a
            href="/tags/from-scratch/"
            class="post-tag no-text-decoration"
          >from-scratch</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted">Share</span>
  <span class="share-icons">
    
    
    

    

      

      <a href="https://twitter.com/intent/tweet?text=Naive%20Bayes%20Simplified%20%7C%20From%20Theory%20to%20Code%20-%20%C3%9Cmit%20Sar%C4%B1%C3%B6z&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fnaive-bayes%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter">
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    

      

      <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fnaive-bayes%2F&text=Naive%20Bayes%20Simplified%20%7C%20From%20Theory%20to%20Code%20-%20%C3%9Cmit%20Sar%C4%B1%C3%B6z" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram">
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

      

      <a href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fnaive-bayes%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Linkedin" aria-label="Linkedin">
        <i class="fa-fw fab fa-linkedin"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none fs-6"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
            <div class="access">
              <!-- Get 5 last posted/updated posts -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/nlp-101/">Getting Started with NLP | A Journey from RNNs to Transformers</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/singular-value-decompositon/">Singular Value Decomposition (SVD)</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/install-apache-cassandra/">Guide to Installing Apache Cassandra on Ubuntu</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/jupyter-lab/">Jupyter Lab Installation on Ubuntu</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/apache_kafka/">Apache Kafka on Ubuntu | Architecture, Installation, and Usage</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning/">machine-learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/from-scratch/">from-scratch</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/algorithms/">algorithms</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/devops/">devops</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/supervised-learning/">supervised-learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/basics/">basics</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/tutorials/">tutorials</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/big-data/">big-data</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/setup/">setup</a>
      
    </div>
  </section>


            </div>

            
              
              






  <div class="toc-border-cover z-3"></div>
  <section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4">
    <h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->















  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/posts/convolutional-neural-networks/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1695070800"
  data-df="ll"
  
>
  Sep 19, 2023
</time>

              <h4 class="pt-0 my-2">Deep Dive into Convolutional Neural Networks (CNNs)</h4>
              <div class="text-muted">
                <p>Convolutional Neural Networks (CNNs) are fundamental to deep learning, revolutionizing computer vision tasks like image recognition and object detection by enhancing how machines interpret visual d...</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/decision-trees/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1688763600"
  data-df="ll"
  
>
  Jul  8, 2023
</time>

              <h4 class="pt-0 my-2">Decision Trees | Growing Your Way to Smarter Decisions</h4>
              <div class="text-muted">
                <p>Decision trees are a foundational tool in machine learning, offering a clear and intuitive method for both classification and regression tasks. This guide provides a detailed exploration of decisio...</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/k-nearest-neighbours-from-scratch/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1680728400"
  data-df="ll"
  
>
  Apr  6, 2023
</time>

              <h4 class="pt-0 my-2">Your Friendly Neighborhood Algorithm is KNN</h4>
              <div class="text-muted">
                <p>The k-Nearest Neighbors (KNN) algorithm is like asking your friends for advice based on who’s closest to you. It figures out your data&#39;s category by looking at its nearest neighbors and deciding wh...</p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/posts/k-nearest-neighbours-from-scratch/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>Your Friendly Neighborhood Algorithm is KNN</p>
    </a>
  

  
    <a
      href="/posts/kmeans/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>K-means Clustering</p>
    </a>
  
</nav>

            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>©
    <time>2025</time>

    
      <a href="https://www.linkedin.com/in/umitsarioz">Ümit Sarıöz</a>.
    

    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p>Using the <a
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="v7.2.4"
        href="https://github.com/cotes2020/jekyll-theme-chirpy"
        target="_blank"
        rel="noopener"
      >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center d-none">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning/">machine-learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/from-scratch/">from-scratch</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/algorithms/">algorithms</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/devops/">devops</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/supervised-learning/">supervised-learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/basics/">basics</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/tutorials/">tutorials</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/big-data/">big-data</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/setup/">setup</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- Embedded scripts -->

    
      
      <!-- The comments switcher -->


    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  
  document.addEventListener('DOMContentLoaded', () => {
    SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('search-results'),
      json: '/assets/js/data/search.json',
      searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{snippet}</p>  </article>',
      noResultsText: '<p class="mt-5">Oops! No results found.</p>',
      templateMiddleware: function(prop, value, template) {
        if (prop === 'categories') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
          }
        }

        if (prop === 'tags') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
          }
        }
      }
    });
  });
</script>

  </body>
</html>

